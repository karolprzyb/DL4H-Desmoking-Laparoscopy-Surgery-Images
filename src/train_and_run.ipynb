{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import json\n",
    "import datetime\n",
    "from typing import Union\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "from torch.optim import Optimizer\n",
    "                              \n",
    "\n",
    "from utils import *\n",
    "from losses import PSNR\n",
    "from SynthTrainer import SynthTrainer\n",
    "import gan\n",
    "import time\n",
    "\n",
    "from synth_data_source import loadData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start by preparing our various models. First we will start with the model described in our target paper \"Desmoking Laparoscopy Surgery Images Using an Image-to-Image Translation Guided by an Embedded Dark Channel\"\n",
    "We will have to define a discriminator and a generator. Note the tables here reflect processing a 512x512 image as opposed to 256x256 as the original paper used. Also note that upon inspecting the paper repository, the tables in the paper appear inaccurate. I recreated these nets to be true to their repository by looking at the logic that generates the nets used.\n",
    "\n",
    "Since the arguments used were not specified in the paper I made a best estimate related to optional arguments based on what I thought would make sense. I also made some modification on where I apply dropout based on some advice from Dr. Florian Richter. It appears dropout was applied on all the 'decoder' layers in the unet, but it equally well could have not been applied at all depending on arguments passed at runtime. My assumption is dropout will be helpful and should be applied at the innermost layers of the decoder.\n",
    "\n",
    "ADD TABLES HERE AS IMAGES. KATEX DOES NOT IMPLEMENT TABULAR..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am only showing this discriminator here. Please see models.py for all the models we will be using. They take up a lot of screen space since I wrote them out explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE PAPER DISCRIMINATOR\n",
    "class Discriminator_demo(torch.nn.Module):\n",
    "    def __init__(self, input_channels:int = 3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sequence = [torch.nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1), \n",
    "                    torch.nn.LeakyReLU(0.2, True)]\n",
    "        \n",
    "        sequence += [torch.nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), \n",
    "                     torch.nn.BatchNorm2d(128),\n",
    "                     torch.nn.LeakyReLU(0.2, True)]\n",
    "        \n",
    "        sequence += [torch.nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1), \n",
    "                     torch.nn.BatchNorm2d(256),\n",
    "                     torch.nn.LeakyReLU(0.2, True)]\n",
    "        \n",
    "        sequence += [torch.nn.ZeroPad2d(2)]\n",
    "        \n",
    "        sequence += [torch.nn.Conv2d(256, 512, kernel_size=4, stride=1), \n",
    "                     torch.nn.BatchNorm2d(512),\n",
    "                     torch.nn.LeakyReLU(0.2, True)]\n",
    "        \n",
    "        sequence += [torch.nn.ZeroPad2d(2)]\n",
    "        \n",
    "        sequence += [torch.nn.Conv2d(512, 1, kernel_size=4, stride=1)]\n",
    "        \n",
    "        self.model = torch.nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import models. Note that UNET is the paper implementation and UNETsmolr is the ablated version with layers x-y taken out. Please reference the code and the numbers to the right of the layers. These layers have different assigned numbers than how it is organized in the report. In the code every individual nn.module has its own layer number instead of being grouped together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note our trainer is located in gan.py. You will want to reference that file along with the inherited class from data_augmentation in order to understand the training, validation and testing. I have included it instead of implementing it here to reduce the length of this notebook.\n",
    "\n",
    "You will also want to reference losses.py for PSNR and other metrics being taken for image quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gan import GANTrainer\n",
    "from losses import PSNR\n",
    "from losses import SSIMLoss\n",
    "from torchmetrics import UniversalImageQualityIndex\n",
    "from libs.pytorch_fsim import fsim\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will setup some arguments which we will use to run our trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {      \n",
    "        'save' : 'C:/Users/Karol/Documents/DL4H/runs/{}'.format(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')),\n",
    "        'batch' : 8,\n",
    "        'lr' : 0.0002,\n",
    "        'epochs' : 60,\n",
    "        'gpu' : 0,\n",
    "        'use_dark_channel' : False,\n",
    "        'load_net' : None,\n",
    "        'run_val_and_test_every_steps' : 1718\n",
    "}\n",
    "\n",
    "args_data = {\n",
    "        'pre_path' : 'C:/Users/Karol/Documents/DL4H',\n",
    "        'cache_subfolder' : '/datasets/cholec80/cache',\n",
    "        'cache_subfolder_test' : '/datasets/cholec80/cache_testset',\n",
    "        'syn_smoke_subfolder' : '/datasets/cholec80/synthetic_smoke/',\n",
    "        'dataset_subfolder' : '/datasets/cholec80/input_formatted',\n",
    "        'dataset_subfolder_test' : '/datasets/cholec80/input_formatted_test'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will start tensorboard. This will allow us to view our model train and look at all the losses as well as output images on validatoin and testing steps. PLEASE UPDATE THE BELOW WITH THE CORRECT PATH TO YOUR 'RUNS' DIRECTORY!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the next line twice may be necessary if you want to see tensorboard in this notebook. Alternatively scroll down for a link to open in your browser. Note that if this step takes 0.0s try changing the port as it did not actually launch tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b45d91d4fbd34f03\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b45d91d4fbd34f03\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%tensorboard --logdir C:/Users/Karol/Documents/DL4H/runs --port 6006"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now open tensorboard here: http://localhost:6006\n",
    "\n",
    "Lets load all our data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 43325 but video length is 43326. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video01\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 70975 but video length is 70976. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video02\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 145700 but video length is 145701. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video03\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 38050 but video length is 38051. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video04\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 58600 but video length is 58601. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video05\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 53825 but video length is 53826. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video06\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 113925 but video length is 113926. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video07\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 37975 but video length is 37976. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video08\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 67550 but video length is 67551. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video09\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 43725 but video length is 43726. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video10\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 80500 but video length is 80501. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video11\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 27250 but video length is 27251. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video12\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 24525 but video length is 24526. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video13\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 42700 but video length is 42701. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video14\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 51450 but video length is 51451. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video15\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 73925 but video length is 73926. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video16\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 32600 but video length is 32601. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video17\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 48550 but video length is 48551. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video18\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 60600 but video length is 60601. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video19\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 36225 but video length is 36226. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted\\video20\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "43326\n",
      "43325\n",
      "70976\n",
      "70975\n",
      "145701\n",
      "145700\n",
      "38051\n",
      "38050\n",
      "58601\n",
      "58600\n",
      "53826\n",
      "53825\n",
      "113926\n",
      "113925\n",
      "37976\n",
      "37975\n",
      "67551\n",
      "67550\n",
      "43726\n",
      "43725\n",
      "80501\n",
      "80500\n",
      "27251\n",
      "27250\n",
      "24526\n",
      "24525\n",
      "42701\n",
      "42700\n",
      "51451\n",
      "51450\n",
      "73926\n",
      "73925\n",
      "32601\n",
      "32600\n",
      "48551\n",
      "48550\n",
      "60601\n",
      "60600\n",
      "36226\n",
      "36225\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 31450 but video length is 31451. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted_test\\video21\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "CSV IS STILL GOOD SO GOOD\n",
      "CSV is good?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of rows in csv file is 38300 but video length is 38301. Recommend deleting csv file so it is recomputed: C:/Users/Karol/Documents/DL4H/datasets/cholec80/input_formatted_test\\video22\\quality_metrics.csv.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM ROWS IN CSV WRONG\n",
      "31451\n",
      "31450\n",
      "38301\n",
      "38300\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data = loadData(args_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we setup our models and run our GAN trainer! This will train and output to tensorboard as it trains. Please set 'save' appropriately in args for log and tensorboard. This step is super easy.\n",
    "\n",
    "For the inner workings please reference models.py for models and gan.py for the trainer.\n",
    "The trainer also uses SynthTrainer.py and Trainer.py from the data_augmentation folder.\n",
    "\n",
    "Most of the basic training is done in gan.py however lots of logging of metrics occurs in SynthTrainer.py\n",
    "\n",
    "Trainer.py contains framework code to generically train various implementations of SynthTrainer. For the purpose of this project its best to mainly stick to gan.py for intuition on the actual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(models)\n",
    "\n",
    "myUNET = models.UNETsmolr()\n",
    "myDisc = models.Discriminator()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at our UNET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of UNETsmolr(\n",
       "  (drp): Dropout(p=0.5, inplace=False)\n",
       "  (sequence): ParameterList(\n",
       "      (0): Object of type: Conv2d\n",
       "      (1): Object of type: LeakyReLU\n",
       "      (2): Object of type: Conv2d\n",
       "      (3): Object of type: BatchNorm2d\n",
       "      (4): Object of type: LeakyReLU\n",
       "      (5): Object of type: Conv2d\n",
       "      (6): Object of type: BatchNorm2d\n",
       "      (7): Object of type: LeakyReLU\n",
       "      (8): Object of type: Conv2d\n",
       "      (9): Object of type: BatchNorm2d\n",
       "      (10): Object of type: LeakyReLU\n",
       "      (11): Object of type: Conv2d\n",
       "      (12): Object of type: BatchNorm2d\n",
       "      (13): Object of type: LeakyReLU\n",
       "      (14): Object of type: Conv2d\n",
       "      (15): Object of type: BatchNorm2d\n",
       "      (16): Object of type: LeakyReLU\n",
       "      (17): Object of type: Conv2d\n",
       "      (18): Object of type: BatchNorm2d\n",
       "      (19): Object of type: LeakyReLU\n",
       "      (20): Object of type: Conv2d\n",
       "      (21): Object of type: ReLU\n",
       "      (22): Object of type: ConvTranspose2d\n",
       "      (23): Object of type: BatchNorm2d\n",
       "      (24): Object of type: ReLU\n",
       "      (25): Object of type: ConvTranspose2d\n",
       "      (26): Object of type: BatchNorm2d\n",
       "      (27): Object of type: ReLU\n",
       "      (28): Object of type: ConvTranspose2d\n",
       "      (29): Object of type: BatchNorm2d\n",
       "      (30): Object of type: ReLU\n",
       "      (31): Object of type: ConvTranspose2d\n",
       "      (32): Object of type: BatchNorm2d\n",
       "      (33): Object of type: ReLU\n",
       "      (34): Object of type: ConvTranspose2d\n",
       "      (35): Object of type: BatchNorm2d\n",
       "      (36): Object of type: ReLU\n",
       "      (37): Object of type: ConvTranspose2d\n",
       "      (38): Object of type: BatchNorm2d\n",
       "      (39): Object of type: ReLU\n",
       "      (40): Object of type: ConvTranspose2d\n",
       "      (41): Object of type: BatchNorm2d\n",
       "      (42): Object of type: ReLU\n",
       "      (43): Object of type: ConvTranspose2d\n",
       "      (44): Object of type: Tanh\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (14): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (17): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (18): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (20): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (21): ReLU(inplace=True)\n",
       "    (22): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU(inplace=True)\n",
       "    (31): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (32): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (35): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (38): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (39): ReLU(inplace=True)\n",
       "    (40): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (41): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (44): Tanh()\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myUNET.parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run training, validation, and test for our firs scenario. This is the ablated UNET and no dark channel. On a 3070+5800x3d this took 8.5 hours. Expect up to 12 hours for the dark channel models to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60:   4%|â–Ž         | 1024/27461 [00:40<07:47, 56.55batch/s]"
     ]
    }
   ],
   "source": [
    "#CODE TO TRAIN SCENARIO 1\n",
    "args['save'] = 'C:/Users/Karol/Documents/DL4H/runs/smol_nodark_60ep{}'.format(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "gan.run(args, myUNET, myDisc, train_data, val_data, test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training, validation, and test for scenario 2. This is full u-net and no dark channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE TO TRAIN SCENARIO 2\n",
    "myUNET2 = models.UNET()\n",
    "myDisc2 = models.Discriminator()\n",
    "args['save'] = 'C:/Users/Karol/Documents/DL4H/runs/full_nodark_60ep{}'.format(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "gan.run(args, myUNET2, myDisc2, train_data, val_data, test_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training, validation, and test for scenario 3. This is ablated u-net and dark channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE TO TRAIN SCENARIO 3\n",
    "myUNET3 = models.UNETsmolr(input_channels=4)\n",
    "myDisc3 = models.Discriminator()\n",
    "args['save'] = 'C:/Users/Karol/Documents/DL4H/runs/smol_dark_60ep{}'.format(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "args['use_dark_channel'] = True\n",
    "gan.run(args, myUNET3, myDisc3, train_data, val_data, test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training, validation, and test for scenario 4. This is full u-net and dark channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(gan)\n",
    "#CODE TO TRAIN SCENARIO 4\n",
    "myUNET4 = models.UNET(input_channels=4)\n",
    "myDisc4 = models.Discriminator()\n",
    "args['save'] = 'C:/Users/Karol/Documents/DL4H/runs/full_dark_60ep{}'.format(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "args['use_dark_channel'] = True\n",
    "gan.run(args, myUNET4, myDisc4, train_data, val_data, test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must run testing on all 4 scenarios. Load in all the models at each epoch so we can plot metrics. (INTEGRATE THIS INTO TRAIN AND VALIDATE??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YES?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL4H_CS598",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
